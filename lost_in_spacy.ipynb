{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Lost in spaCy"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dependencies"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import pandas as pd #This manages data frames\r\n",
    "import spacy # SpaCy is a text analysis tool\r\n",
    "nlp = spacy.load(\"en_core_web_lg\") #this is the library used in nlp"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Data\r\n",
    "> ðŸ“ŒI am using a sample data set to do this that is a CSV with two columns called id and text, the file is very simple by design so that the only thing going in is what is needed to come out i.e. the id of the text value and the text value - you can then join this up any way you like in Python or Power BI but the idea is to keep things as simple as possible. The text I am using is a dataset of tweets for demonstration purposes."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "df = pd.read_csv('./data/text_small_example.csv', nrows=2) #loading just the first 2 rows to demonstrate code\r\n",
    "pd.set_option('display.max_colwidth', None) #changing column width to show full text\r\n",
    "df\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   id  \\\n",
       "0   1   \n",
       "1   2   \n",
       "\n",
       "                                                                                    text  \n",
       "0  @elephantbird Hey dear, Happy Friday to You  Already had your rice's bowl for lunch ?  \n",
       "1                             Ughhh layin downnnn    Waiting for zeina to cook breakfast  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>@elephantbird Hey dear, Happy Friday to You  Already had your rice's bowl for lunch ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ughhh layin downnnn    Waiting for zeina to cook breakfast</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Position of Speech"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "#create a for loop of the rows in the df dataframe\r\n",
    "for idx, row in df.iterrows():\r\n",
    "    #checks to see if the value in text is a string i.e. contains data if so continue\r\n",
    "    if not isinstance(row['text'], str):\r\n",
    "        continue\r\n",
    "    #doc is the nlp results of the current text value\r\n",
    "    doc = nlp(row['text'])\r\n",
    "    #for loop for each token of the outputs\r\n",
    "    for token in doc:\r\n",
    "        #print id of row, token text and token pos code\r\n",
    "        print(row[\"id\"],token.text,token.pos_)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1 @elephantbird NOUN\n",
      "1 Hey INTJ\n",
      "1 dear INTJ\n",
      "1 , PUNCT\n",
      "1 Happy PROPN\n",
      "1 Friday PROPN\n",
      "1 to ADP\n",
      "1 You PRON\n",
      "1   SPACE\n",
      "1 Already ADV\n",
      "1 had VERB\n",
      "1 your PRON\n",
      "1 rice NOUN\n",
      "1 's PART\n",
      "1 bowl NOUN\n",
      "1 for ADP\n",
      "1 lunch NOUN\n",
      "1 ? PUNCT\n",
      "2 Ughhh INTJ\n",
      "2 layin PROPN\n",
      "2 downnnn ADV\n",
      "2     SPACE\n",
      "2 Waiting VERB\n",
      "2 for ADP\n",
      "2 zeina PROPN\n",
      "2 to PART\n",
      "2 cook VERB\n",
      "2 breakfast NOUN\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Named Entity Regcognition\r\n",
    "> ðŸ“Œ This is almost identical to the POS code and works exactly the same way except instead of using the POS outputs of nlp it uses the entity outputs "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "#create a for loop of the rows in the df dataframe\r\n",
    "for idx, row in df.iterrows():\r\n",
    "    #checks to see if the value in text is a string i.e. contains data if so continue\r\n",
    "    if not isinstance(row['text'], str):\r\n",
    "        continue\r\n",
    "    #doc is the nlp results of the current text value\r\n",
    "    doc = nlp(row['text'])\r\n",
    "    #for loop for each entity of the outputs\r\n",
    "    for e in doc.ents:\r\n",
    "        #print id of row, entity text and entity label\r\n",
    "        print(row[\"id\"],e.text,e.label_)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1 @elephantbird ORG\n",
      "1 Friday DATE\n",
      "2 Ughhh PERSON\n",
      "2 zeina PERSON\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "48cc7c787c9e7337c2fc1738d63fa3d86a77ffde0048b7ccfde354c54d52995c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}